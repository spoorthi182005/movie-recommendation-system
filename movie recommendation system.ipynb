{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu0Pf8NFBoOwWhT83I0pVA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spoorthi182005/movie-recommendation-system/blob/main/movie%20recommendation%20system.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Movie Recommendation System**\n",
        "\n",
        "**Objective**\n",
        "\n",
        "The objective of a movie recommendation system is to predict and suggest movies that a user is likely to enjoy based on their past viewing history and preferences, as well as similarities with other users' behaviors. This aims to enhance user satisfaction and engagement by providing personalized content.\n",
        "\n",
        "**Data Source**\n",
        "\n",
        "A movie recommendation system data source typically includes information on user ratings, movie metadata (such as genre, director, cast, and release year), and user demographics. Common datasets used for this purpose are the MovieLens datasets, which provide extensive user-movie rating data.\n",
        "\n",
        "**import library**"
      ],
      "metadata": {
        "id": "jMHY_QaFBnXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "import spacy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "from surprise import Dataset, Reader, SVD, accuracy\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Load the movie rating data\n",
        "# Assume the data is in a pandas dataframe df with columns: userId, movieId, rating\n",
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], Reader(rating_scale=(0.5, 5.0)))\n",
        "\n",
        "# Split the data into train and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Use the SVD algorithm for recommendations\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the trainset\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Test the algorithm on the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Compute and print the RMSE\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "\n",
        "# Assume you have a pandas dataframe 'movies' with columns: 'title' and 'description'\n",
        "\n",
        "# Create TF-IDF matrix for movie descriptions\n",
        "tfidf = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = tfidf.fit_transform(movies['description'])\n",
        "\n",
        "# Compute cosine similarity matrix\n",
        "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Function to get movie recommendations based on the cosine similarity score\n",
        "def get_recommendations(title, cosine_sim=cosine_sim):\n",
        "    idx = movies[movies['title'] == title].index[0]\n",
        "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
        "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
        "    sim_scores = sim_scores[1:11]\n",
        "    movie_indices = [i[0] for i in sim_scores]\n",
        "    return movies['title'].iloc[movie_indices]\n",
        "\n",
        "# Example usage\n",
        "print(get_recommendations('The Godfather'))\n",
        ""
      ],
      "metadata": {
        "id": "m8XlktclBoWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Describe Data**"
      ],
      "metadata": {
        "id": "HP0Zz-B-B3hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of data description for a movie recommendation system\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load the data\n",
        "movies_df = pd.read_csv('movies.csv')        # Information about the movies\n",
        "ratings_df = pd.read_csv('ratings.csv')      # User ratings for the movies\n",
        "users_df = pd.read_csv('users.csv')          # Information about the users\n",
        "\n",
        "# Display the first few rows of each DataFrame to understand their structure\n",
        "print(\"Movies DataFrame:\")\n",
        "print(movies_df.head())\n",
        "\n",
        "print(\"\\nRatings DataFrame:\")\n",
        "print(ratings_df.head())\n",
        "\n",
        "print(\"\\nUsers DataFrame:\")\n",
        "print(users_df.head())\n",
        "\n",
        "# Movies DataFrame columns:\n",
        "# - movie_id: unique identifier for each movie\n",
        "# - title: title of the movie\n",
        "# - genres: genres associated with the movie (separated by | if multiple)\n",
        "\n",
        "# Ratings DataFrame columns:\n",
        "# - user_id: unique identifier for each user\n",
        "# - movie_id: unique identifier for each movie\n",
        "# - rating: rating given by the user to the movie (typically on a scale from 1 to 5)\n",
        "# - timestamp: time at which the rating was given\n",
        "\n",
        "# Users DataFrame columns:\n",
        "# - user_id: unique identifier for each user\n",
        "# - age: age of the user\n",
        "# - gender: gender of the user (e.g., M or F)\n",
        "# - occupation: occupation of the user\n",
        "# - zip_code: ZIP code of the user\n",
        ""
      ],
      "metadata": {
        "id": "cOXlnX_6B_6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Visualization**\n",
        "\n"
      ],
      "metadata": {
        "id": "m5uQ7iSECFVK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load the dataset\n",
        "movies = pd.read_csv('movies.csv')\n",
        "ratings = pd.read_csv('ratings.csv')\n",
        "\n",
        "# Merge datasets\n",
        "data = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# Visualization 1: Distribution of movie ratings\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data['rating'], bins=10, kde=False)\n",
        "plt.title('Distribution of Movie Ratings')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 2: Top 10 Most Rated Movies\n",
        "top_movies = data['title'].value_counts().head(10)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_movies.values, y=top_movies.index, palette='viridis')\n",
        "plt.title('Top 10 Most Rated Movies')\n",
        "plt.xlabel('Number of Ratings')\n",
        "plt.ylabel('Movie Title')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 3: Average Rating of Top 10 Most Rated Movies\n",
        "top_rated_movies = data.groupby('title')['rating'].mean().sort_values(ascending=False).head(10)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=top_rated_movies.values, y=top_rated_movies.index, palette='viridis')\n",
        "plt.title('Top 10 Highest Rated Movies')\n",
        "plt.xlabel('Average Rating')\n",
        "plt.ylabel('Movie Title')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 4: Rating Distribution by Genre\n",
        "data['genres'] = data['genres'].str.split('|')\n",
        "genres_data = data.explode('genres')\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.boxplot(x='rating', y='genres', data=genres_data, palette='Set2')\n",
        "plt.title('Rating Distribution by Genre')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()\n",
        "\n",
        "# Visualization 5: Number of Ratings per Genre\n",
        "genre_counts = genres_data['genres'].value_counts()\n",
        "plt.figure(figsize=(14, 8))\n",
        "sns.barplot(x=genre_counts.values, y=genre_counts.index, palette='Set3')\n",
        "plt.title('Number of Ratings per Genre')\n",
        "plt.xlabel('Number of Ratings')\n",
        "plt.ylabel('Genre')\n",
        "plt.show()\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "JwV7KQReCIFc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "WmAQ-PgpCNSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load datasets\n",
        "movies = pd.read_csv('movies.csv')  # Movies metadata\n",
        "ratings = pd.read_csv('ratings.csv')  # User ratings\n",
        "\n",
        "# Display first few rows of the datasets\n",
        "print(\"Movies DataFrame:\")\n",
        "print(movies.head())\n",
        "\n",
        "print(\"\\nRatings DataFrame:\")\n",
        "print(ratings.head())\n",
        "\n",
        "# Merge the datasets on 'movieId'\n",
        "merged_df = pd.merge(ratings, movies, on='movieId')\n",
        "\n",
        "# Display first few rows of the merged dataset\n",
        "print(\"\\nMerged DataFrame:\")\n",
        "print(merged_df.head())\n",
        "\n",
        "# Drop unnecessary columns (if any)\n",
        "# For example, if there's a 'timestamp' column in the ratings data\n",
        "merged_df = merged_df.drop(columns=['timestamp'])\n",
        "\n",
        "# Display the data after dropping unnecessary columns\n",
        "print(\"\\nDataFrame after dropping unnecessary columns:\")\n",
        "print(merged_df.head())\n",
        "\n",
        "# Encode categorical data (e.g., genres)\n",
        "# One-hot encoding for 'genres' column\n",
        "merged_df['genres'] = merged_df['genres'].str.split('|')\n",
        "merged_df = merged_df.explode('genres')\n",
        "merged_df = pd.get_dummies(merged_df, columns=['genres'])\n",
        "\n",
        "# Display the data after encoding\n",
        "print(\"\\nDataFrame after encoding genres:\")\n",
        "print(merged_df.head())\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shape of the training and testing sets\n",
        "print(f\"\\nTraining data shape: {train_data.shape}\")\n",
        "print(f\"Testing data shape: {test_data.shape}\")\n",
        "\n",
        "# Standardize the ratings\n",
        "scaler = StandardScaler()\n",
        "train_data['rating'] = scaler.fit_transform(train_data[['rating']])\n",
        "test_data['rating'] = scaler.transform(test_data[['rating']])\n",
        "\n",
        "# Display the first few rows of the standardized data\n",
        "print(\"\\nTraining data after standardization:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"\\nTesting data after standardization:\")\n",
        "print(test_data.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "C6OFc1KlCV8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Target Variable (y) and Feature Variables (X)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "M8GwNrAhCbHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example dataset with user ratings\n",
        "data = {\n",
        "    'user_id': [1, 1, 1, 2, 2, 3, 3, 4],\n",
        "    'movie_id': [101, 102, 103, 101, 104, 102, 103, 105],\n",
        "    'rating': [5, 3, 4, 4, 2, 5, 3, 4],\n",
        "    'timestamp': [964982703, 964981247, 964982224, 964983815, 964982931, 964982791, 964981632, 964982176]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Define the target variable (y) - Ratings\n",
        "y = df['rating']\n",
        "\n",
        "# Define feature variables (X) - user_id, movie_id, and timestamp\n",
        "X = df[['user_id', 'movie_id', 'timestamp']]\n",
        "\n",
        "print(\"Feature Variables (X):\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nTarget Variable (y):\")\n",
        "print(y.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "ZTTjkP4VCg64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test Split**\n",
        "\n"
      ],
      "metadata": {
        "id": "GFaD39dpCmuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming you have a DataFrame 'ratings' with columns: 'userId', 'movieId', 'rating'\n",
        "# Sample data loading, replace this with actual data loading\n",
        "data = {\n",
        "    'userId': [1, 1, 2, 2, 3, 3, 4, 4, 5, 5],\n",
        "    'movieId': [1, 2, 2, 3, 3, 4, 4, 5, 5, 1],\n",
        "    'rating': [4, 5, 5, 3, 4, 2, 3, 4, 5, 3]\n",
        "}\n",
        "ratings = pd.DataFrame(data)\n",
        "\n",
        "# Perform train-test split\n",
        "train, test = train_test_split(ratings, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the results\n",
        "print(\"Train set:\")\n",
        "print(train)\n",
        "print(\"\\nTest set:\")\n",
        "print(test)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "MAursuqWCpqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modeling**"
      ],
      "metadata": {
        "id": "zsYKF4N1CudW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Surprise library if you haven't already\n",
        "# !pip install scikit-surprise\n",
        "\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import SVD  # Example algorithm, you can choose others like KNN, etc.\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the movielens-100k dataset (you can replace with your own dataset)\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "# Define a reader to specify the rating scale\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset with the reader\n",
        "dataset = data.build_full_trainset()\n",
        "trainset, testset = train_test_split(dataset, test_size=0.2)\n",
        "\n",
        "# Choose an algorithm (SVD here) and train it on the dataset\n",
        "algo = SVD()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Predict ratings for the testset\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Evaluate the model by computing Root Mean Squared Error (RMSE)\n",
        "accuracy.rmse(predictions)\n",
        "\n",
        "# Make recommendations for a user\n",
        "user_id = str(196)  # Example user ID\n",
        "items_to_predict = [str(item) for item in range(1, 100)]  # Example items to predict\n",
        "predicted_ratings = {}\n",
        "for item_id in items_to_predict:\n",
        "    predicted_ratings[item_id] = algo.predict(user_id, item_id).est\n",
        "\n",
        "# Get top n recommendations\n",
        "n = 10\n",
        "top_n = sorted(predicted_ratings.items(), key=lambda x: x[1], reverse=True)[:n]\n",
        "for movie_id, rating in top_n:\n",
        "    print(f'Movie ID: {movie_id}, Estimated Rating: {rating}')\n",
        ""
      ],
      "metadata": {
        "id": "NjMniOOaCxwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Evaluation**\n"
      ],
      "metadata": {
        "id": "BA576L4gC3J0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Example actual ratings and predicted ratings\n",
        "actual_ratings = [4, 3, 5, 2, 4, 1, 5, 3, 4, 2]\n",
        "predicted_ratings = [3.8, 2.9, 4.5, 2.1, 3.7, 1.2, 4.8, 3.1, 3.9, 2.3]\n",
        "\n",
        "# Evaluate using Mean Squared Error (MSE)\n",
        "mse = mean_squared_error(actual_ratings, predicted_ratings)\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")"
      ],
      "metadata": {
        "id": "Uo7KJ018C5Xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "wrHnpcNPC88p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Define the format of the data\n",
        "reader = Reader(line_format='user item rating', sep=',')\n",
        "\n",
        "# Load the dataset\n",
        "data = Dataset.load_from_file('path_to_your_dataset.csv', reader=reader)\n",
        "\n",
        "# Use the SVD algorithm\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the dataset\n",
        "trainset = data.build_full_trainset()\n",
        "algo.fit(trainset)\n",
        "\n",
        "# Define a function to predict ratings\n",
        "def predict_rating(user_id, item_id):\n",
        "    prediction = algo.predict(user_id, item_id)\n",
        "    return prediction.est\n",
        "\n",
        "# Example usage:\n",
        "user_id = 'user1'\n",
        "item_id = 'item1'\n",
        "predicted_rating = predict_rating(user_id, item_id)\n",
        "print(f'Predicted rating for user {user_id} on item {item_id}: {predicted_rating}')\n",
        "\n"
      ],
      "metadata": {
        "id": "LLxtN4ZXC_3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation**"
      ],
      "metadata": {
        "id": "hcTX0qE0DEq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A movie recommendation system is a technology that suggests movies to users based on their preferences, past viewing history, and other relevant factors. It employs techniques such as collaborative filtering, content-based filtering, and hybrid approaches to provide personalized recommendations. These systems leverage machine learning algorithms to analyze large datasets of user behavior and movie characteristics, aiming to enhance user satisfaction by suggesting relevant and appealing movies. Overall, movie recommendation systems play a crucial role in enhancing user experience and engagement in streaming platforms and movie databases."
      ],
      "metadata": {
        "id": "xY931z4nDHzE"
      }
    }
  ]
}